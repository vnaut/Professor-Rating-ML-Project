{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vnaut/Professor-Rating-ML-Project/blob/main/PlanetTerp_Professors_ML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YL9OMpXBquh"
      },
      "outputs": [],
      "source": [
        "# at the top of your notebook\n",
        "!pip install flair --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E9iQfgFyjF1"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import time\n",
        "import json\n",
        "\n",
        "BASE_URL = \"https://planetterp.com/api/v1\"\n",
        "DELAY = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTyJRE0zz1Fz"
      },
      "outputs": [],
      "source": [
        "def get_professors(limit=100, offset=0, include_reviews=False, prof_type=None):\n",
        "    \"\"\"\n",
        "    Fetch a page of professors.\n",
        "    :param limit: max records (1-100)\n",
        "    :param offset: records to skip\n",
        "    :param include_reviews: whether to include reviews\n",
        "    :param prof_type: 'professor' or 'ta' or None\n",
        "    :return: list of professor dicts\n",
        "    \"\"\"\n",
        "    params = {\n",
        "        'limit': limit,\n",
        "        'offset': offset,\n",
        "    }\n",
        "    if include_reviews:\n",
        "        params['reviews'] = 'true'\n",
        "    if prof_type:\n",
        "        params['type'] = prof_type\n",
        "\n",
        "    resp = requests.get(f\"{BASE_URL}/professors\", params=params)\n",
        "    resp.raise_for_status()\n",
        "    return resp.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvlD1P-dz4RL"
      },
      "outputs": [],
      "source": [
        "def fetch_all_professors(include_reviews=False, prof_type=None):\n",
        "    \"\"\"\n",
        "    Fetches all professors via pagination.\n",
        "    \"\"\"\n",
        "    all_profs = []\n",
        "    offset = 0\n",
        "    while True:\n",
        "        batch = get_professors(limit=100, offset=offset,\n",
        "                               include_reviews=include_reviews,\n",
        "                               prof_type=prof_type)\n",
        "        if not batch:\n",
        "            break\n",
        "        all_profs.extend(batch)\n",
        "        offset += len(batch)\n",
        "        time.sleep(DELAY)\n",
        "    return all_profs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rroKuQSe0YAt"
      },
      "outputs": [],
      "source": [
        "def get_courses(department=None, limit=100, offset=0, include_reviews=False):\n",
        "    \"\"\"\n",
        "    Fetch a page of courses.\n",
        "    :param department: 4-char dept code, e.g. 'CMSC'\n",
        "    \"\"\"\n",
        "    params = {\n",
        "        'limit': limit,\n",
        "        'offset': offset,\n",
        "    }\n",
        "    if department:\n",
        "        params['department'] = department\n",
        "    if include_reviews:\n",
        "        params['reviews'] = 'true'\n",
        "\n",
        "    resp = requests.get(f\"{BASE_URL}/courses\", params=params)\n",
        "    resp.raise_for_status()\n",
        "    return resp.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1a6rJmF0aVI"
      },
      "outputs": [],
      "source": [
        "def fetch_all_courses(department=None, include_reviews=False):\n",
        "    \"\"\"\n",
        "    Fetches all courses (optionally filtered by department).\n",
        "    \"\"\"\n",
        "    all_courses = []\n",
        "    offset = 0\n",
        "    while True:\n",
        "        batch = get_courses(department=department,\n",
        "                            limit=100, offset=offset,\n",
        "                            include_reviews=include_reviews)\n",
        "        if not batch:\n",
        "            break\n",
        "        all_courses.extend(batch)\n",
        "        offset += len(batch)\n",
        "        time.sleep(DELAY)\n",
        "    return all_courses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XhUNKPb0jlV"
      },
      "outputs": [],
      "source": [
        "def get_grades(course=None, professor=None, semester=None, section=None):\n",
        "    \"\"\"\n",
        "    Fetch grade distributions.\n",
        "    At least one of course or professor must be provided.\n",
        "    :param course: course code string e.g. 'CMSC320'\n",
        "    :param professor: full name string e.g. 'Jon Snow'\n",
        "    :param semester: 'YYYY01' for spring, 'YYYY08' for fall\n",
        "    :param section: section code string, e.g. '0101'\n",
        "    \"\"\"\n",
        "    params = {}\n",
        "    if course:\n",
        "        params['course'] = course\n",
        "    if professor:\n",
        "        params['professor'] = professor\n",
        "    if semester:\n",
        "        params['semester'] = semester\n",
        "    if section:\n",
        "        params['section'] = section\n",
        "    if not params:\n",
        "        raise ValueError(\"Must specify at least course or professor\")\n",
        "\n",
        "    resp = requests.get(f\"{BASE_URL}/grades\", params=params)\n",
        "    resp.raise_for_status()\n",
        "    return resp.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UkUtHr00kZ7"
      },
      "outputs": [],
      "source": [
        "def save_json(data, filename):\n",
        "    \"\"\"\n",
        "    Utility to save JSON data to a file.\n",
        "    \"\"\"\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(data, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGDVCriW0scw"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    # Example: Fetch all professors with reviews\n",
        "    print(\"Fetching all professors with reviews...\")\n",
        "    professors = fetch_all_professors(include_reviews=True)\n",
        "    print(f\"Retrieved {len(professors)} professors\")\n",
        "    save_json(professors, 'professors.json')\n",
        "\n",
        "    # Collect unique courses from professors\n",
        "    course_codes = set()\n",
        "    for prof in professors:\n",
        "        for code in prof.get('courses', []):\n",
        "            course_codes.add(code)\n",
        "\n",
        "    # Fetch course details for each unique code\n",
        "    print(f\"Fetching details for {len(course_codes)} courses...\")\n",
        "    courses = {}\n",
        "    for code in course_codes:\n",
        "        data = requests.get(f\"{BASE_URL}/course\", params={'name': code}).json()\n",
        "        courses[code] = data\n",
        "        time.sleep(DELAY)\n",
        "    save_json(courses, 'courses.json')\n",
        "\n",
        "    # Fetch grade distributions for each professor-course pair\n",
        "    print(\"Fetching grade distributions...\")\n",
        "    grades = []\n",
        "    for prof in professors:\n",
        "        name = prof['name']\n",
        "        for code in prof.get('courses', []):\n",
        "            try:\n",
        "                gd = get_grades(course=code, professor=name)\n",
        "                grades.extend(gd)\n",
        "            except Exception as e:\n",
        "                print(f\"Error fetching grades for {code} by {name}: {e}\")\n",
        "            time.sleep(DELAY)\n",
        "    save_json(grades, 'grades.json')\n",
        "\n",
        "    print(\"Data fetching complete. Files saved: professors.json, courses.json, grades.json\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ROg_5O57FMc"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import json\n",
        "\n",
        "BASE_URL = \"https://planetterp.com/api/v1\"\n",
        "MAX_WORKERS = 10  # adjust based on your network/API limits\n",
        "\n",
        "def fetch_all_professors(session, limit=100):\n",
        "    profs, offset = [], 0\n",
        "    while True:\n",
        "        resp = session.get(f\"{BASE_URL}/professors\", params={'limit': limit, 'offset': offset})\n",
        "        resp.raise_for_status()\n",
        "        batch = resp.json()\n",
        "        if not batch:\n",
        "            break\n",
        "        profs.extend(batch)\n",
        "        offset += len(batch)\n",
        "    return profs\n",
        "\n",
        "def fetch_all_courses(session, limit=100):\n",
        "    courses, offset = [], 0\n",
        "    while True:\n",
        "        resp = session.get(f\"{BASE_URL}/courses\", params={'limit': limit, 'offset': offset})\n",
        "        resp.raise_for_status()\n",
        "        batch = resp.json()\n",
        "        if not batch:\n",
        "            break\n",
        "        courses.extend(batch)\n",
        "        offset += len(batch)\n",
        "    return courses\n",
        "\n",
        "def fetch_grades_for_course(session, course_code):\n",
        "    resp = session.get(f\"{BASE_URL}/grades\", params={'course': course_code})\n",
        "    resp.raise_for_status()\n",
        "    return resp.json()\n",
        "\n",
        "def main():\n",
        "    session = requests.Session()\n",
        "\n",
        "    # 1) Bulk fetch professors (no reviews) and courses\n",
        "    print(\"Fetching professors...\")\n",
        "    profs = fetch_all_professors(session)\n",
        "    print(f\"  → Retrieved {len(profs)} professors.\")\n",
        "\n",
        "    print(\"Fetching courses...\")\n",
        "    courses = fetch_all_courses(session)\n",
        "    print(f\"  → Retrieved {len(courses)} courses.\")\n",
        "\n",
        "    # 2) Concurrently fetch grades per course\n",
        "    course_codes = [f\"{c['department']}{c['course_number']}\" for c in courses]\n",
        "    print(\"Fetching grades for each course in parallel...\")\n",
        "    grades = []\n",
        "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
        "        futures = {executor.submit(fetch_grades_for_course, session, code): code for code in course_codes}\n",
        "        for future in as_completed(futures):\n",
        "            code = futures[future]\n",
        "            try:\n",
        "                grades.extend(future.result())\n",
        "            except Exception as e:\n",
        "                print(f\"Error fetching grades for {code}: {e}\")\n",
        "\n",
        "    # 3) Save to files\n",
        "    with open('professors.json', 'w') as f:\n",
        "        json.dump(profs, f, indent=2)\n",
        "    with open('courses.json', 'w') as f:\n",
        "        json.dump({f\"{c['department']}{c['course_number']}\": c for c in courses}, f, indent=2)\n",
        "    with open('grades.json', 'w') as f:\n",
        "        json.dump(grades, f, indent=2)\n",
        "\n",
        "    print(\"Done! Data saved to professors.json, courses.json, grades.json\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4Y9nYEX_ZUg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1) Load the raw JSON dumps (produced by fetch_planetterp_data.py)\n",
        "with open('professors.json') as f:\n",
        "    profs = json.load(f)\n",
        "with open('courses.json') as f:\n",
        "    courses = json.load(f)\n",
        "with open('grades.json')  as f:\n",
        "    grades = json.load(f)\n",
        "\n",
        "# 2) Make DataFrames\n",
        "prof_df   = pd.DataFrame(profs)                                     # contains name, slug, courses list, average_rating (TARGET)\n",
        "courses_df = (\n",
        "    pd.DataFrame.from_dict(courses, orient='index')\n",
        "      .rename_axis('course_code')\n",
        "      .reset_index()\n",
        ")                                                                   # course_code, department, credits, average_gpa, etc.\n",
        "grades_df = pd.DataFrame(grades)                                     # one row per (course, prof, semester, section) grade distribution\n",
        "\n",
        "# 3) Course‑level aggregates per professor\n",
        "#    • how many distinct courses they’ve taught\n",
        "#    • average course credits\n",
        "#    • average of course‑level avg_gpa\n",
        "course_feats = (\n",
        "    prof_df\n",
        "      .explode('courses')\n",
        "      .merge(courses_df[['course_code','credits','average_gpa']],\n",
        "             left_on='courses', right_on='course_code', how='left')\n",
        "      .groupby('name')\n",
        "      .agg(\n",
        "         num_courses     = ('course_code',   'nunique'),\n",
        "         avg_credits     = ('credits',       'mean'),\n",
        "         avg_course_gpa  = ('average_gpa',   'mean')\n",
        "      )\n",
        ")\n",
        "\n",
        "# 4) Grade‑distribution aggregates per professor\n",
        "#    We sum up all sections and turn raw counts into proportions\n",
        "grade_cols = ['A+','A','A-','B+','B','B-','C+','C','C-','D+','D','D-','F','W','Other']\n",
        "grades_sum = (\n",
        "    grades_df\n",
        "      .groupby('professor')[grade_cols]\n",
        "      .sum()\n",
        ")\n",
        "grades_sum['total'] = grades_sum.sum(axis=1)\n",
        "for g in grade_cols:\n",
        "    grades_sum[f'prop_{g}'] = grades_sum[g] / grades_sum['total']\n",
        "\n",
        "# 5) Stitch everything together (one row per professor)\n",
        "dataset = (\n",
        "    prof_df\n",
        "      .set_index('name')[['slug','average_rating']]\n",
        "      .join(course_feats)\n",
        "      .join(grades_sum[[f'prop_{g}' for g in ['A+','A','A-','B+','B','B-','W']]])\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "# 6) Quick sanity‑check\n",
        "print(dataset.tail())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMVTaE6dBY-o"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# 1) Load raw professors + their reviews\n",
        "with open('professors.json') as f:\n",
        "    profs = json.load(f)\n",
        "\n",
        "# 2) Flatten out reviews into a DataFrame\n",
        "#    (we assume each prof dict has a key \"reviews\" which is a list of\n",
        "#     objects containing at least \"review_text\" and \"expected_grade\")\n",
        "rows = []\n",
        "for p in profs:\n",
        "    name = p['name']\n",
        "    for r in p.get('reviews', []):\n",
        "        rows.append({\n",
        "            'professor':       name,\n",
        "            'text':            r.get('review_text',''),\n",
        "            'expected_grade':  r.get('expected_grade', None)\n",
        "        })\n",
        "\n",
        "rev_df = pd.DataFrame(rows)\n",
        "\n",
        "# peek at the first professor’s first review\n",
        "import pprint\n",
        "pprint.pprint(profs[0].get('reviews', [])[0])\n",
        "\n",
        "\n",
        "# 3) Run sentiment analysis\n",
        "#    Example using Flair:\n",
        "from flair.models import TextClassifier\n",
        "from flair.data   import Sentence\n",
        "\n",
        "classifier = TextClassifier.load('en-sentiment')\n",
        "\n",
        "def flair_sentiment(txt):\n",
        "    s = Sentence(txt)\n",
        "    classifier.predict(s)\n",
        "    return s.labels[0].value     # either \"POSITIVE\" or \"NEGATIVE\"\n",
        "\n",
        "rev_df['sentiment'] = rev_df['text'].apply(flair_sentiment)\n",
        "\n",
        "# 4) Map letter grades to numeric so we can average\n",
        "grade_to_num = {\n",
        "    'A+': 4.0, 'A': 4.0, 'A-': 3.7,\n",
        "    'B+': 3.3, 'B':  3.0, 'B-': 2.7,\n",
        "    'C+': 2.3, 'C':  2.0, 'C-': 1.7,\n",
        "    'D+': 1.3, 'D':  1.0, 'D-': 0.7,\n",
        "    'F':  0.0\n",
        "}\n",
        "rev_df['grade_num'] = rev_df['expected_grade'].map(grade_to_num)\n",
        "\n",
        "# 5) Aggregate by professor\n",
        "sent_counts = (rev_df\n",
        "  .groupby(['professor','sentiment'])\n",
        "  .size()\n",
        "  .unstack(fill_value=0)\n",
        ")\n",
        "\n",
        "num_ratings   = rev_df.groupby('professor').size().rename('num_ratings')\n",
        "avg_grade_num = rev_df.groupby('professor')['grade_num'].mean().rename('avg_grade_num')\n",
        "\n",
        "# 6) Convert back to a letter grade (round to nearest standard cut)\n",
        "def num_to_letter(x):\n",
        "    if   x >= 3.85: return 'A'\n",
        "    elif x >= 3.5:  return 'A-'\n",
        "    elif x >= 3.15: return 'B+'\n",
        "    elif x >= 2.85: return 'B'\n",
        "    elif x >= 2.5:  return 'B-'\n",
        "    elif x >= 2.15: return 'C+'\n",
        "    elif x >= 1.85: return 'C'\n",
        "    elif x >= 1.5:  return 'C-'\n",
        "    elif x >= 1.15: return 'D+'\n",
        "    elif x >= 0.85: return 'D'\n",
        "    elif x >= 0.5:  return 'D-'\n",
        "    else:           return 'F'\n",
        "\n",
        "summary = (\n",
        "    sent_counts\n",
        "      .join(num_ratings)\n",
        "      .join(avg_grade_num)\n",
        "      .reset_index()\n",
        ")\n",
        "summary['avg_expected_grade'] = summary['avg_grade_num'].apply(num_to_letter)\n",
        "\n",
        "# 7) Final table\n",
        "print(summary[['professor','POSITIVE','NEGATIVE','num_ratings','avg_expected_grade']])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyND3R0Wj3hPB5K36OdwCt5E",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}